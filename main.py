import os
import subprocess
from datetime import datetime
from voice.speaker import speak
from voice.listener import listen
from ai.gemini_ai import get_response
from tasks.general_tasks import execute_command

# --- Tamil to Hindi Translator Imports ---
from translator.speech_input import recognize_speech
from translator.translator_engine import translate_tamil_to_hindi
from translator.speech_output import speak_text

# --- GIF Display Imports ---
import speech_recognition as sr
import tkinter as tk
from PIL import Image, ImageTk, ImageSequence

# --- Spotify Integration Imports ---
import spotipy
from spotipy.oauth2 import SpotifyOAuth
import webbrowser
from config import SPOTIFY_CLIENT_ID, SPOTIFY_CLIENT_SECRET, SPOTIFY_REDIRECT_URI

# --- Logging Function ---
def log_conversation(role, message):
    log_path = os.path.join(os.getcwd(), "conversation_log.txt")
    with open(log_path, "a", encoding="utf-8") as log_file:
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_file.write(f"[{timestamp}] {role}: {message}\n")

# --- GIF Display Configuration ---
speech_to_gif = {
    "hello": "hello.gif",
    "thank you": "thanks.gif",
    "yes": "yes.gif",
    "no": "no.gif"
}

def listen_and_show_gif():
    """Listen for speech and display corresponding GIF"""
    recognizer = sr.Recognizer()
    mic = sr.Microphone()

    with mic as source:
        print("ЁЯОд Listening for GIF trigger words...")
        speak("GIF роорпБро▒рпИропро┐ро▓рпН роХрпЗроЯрпНроХро┐ро▒рпЗройрпН...")
        audio = recognizer.listen(source)

    try:
        command = recognizer.recognize_google(audio).lower()
        print(f"ЁЯЧгя╕П You said: {command}")
        log_conversation("User", command)
        
        for word in speech_to_gif:
            if word in command:
                gif_path = f"zara_assets/gif_output/{speech_to_gif[word]}"
                show_gif(gif_path)
                break
        else:
            print("тЭМ No matching GIF found for command")
            speak("роЕроирпНрод ро╡ро╛ро░рпНродрпНродрпИроХрпНроХрпБ GIF роХро┐роЯрпИроХрпНроХро╡ро┐ро▓рпНро▓рпИ.")
    except Exception as e:
        print(f"тЭМ Could not understand audio: {e}")
        speak("роЙроЩрпНроХро│рпН рокрпЗроЪрпНроЪрпИ рокрпБро░ро┐роирпНродрпБроХрпКро│рпНро│ роорпБроЯро┐ропро╡ро┐ро▓рпНро▓рпИ.")

def show_gif(gif_path):
    """Display animated GIF in a window"""
    if not os.path.exists(gif_path):
        print(f"тЭМ GIF file not found: {gif_path}")
        speak("GIF роХрпЛрокрпНрокрпБ роХро╛рогро╡ро┐ро▓рпНро▓рпИ.")
        return
    
    try:
        root = tk.Tk()
        root.title("Zara GIF Output")
        root.geometry("400x400")

        gif = Image.open(gif_path)
        frames = [ImageTk.PhotoImage(frame.copy().convert('RGBA')) for frame in ImageSequence.Iterator(gif)]
        
        label = tk.Label(root)
        label.pack(expand=True)

        def update(index):
            frame = frames[index]
            index = (index + 1) % len(frames)
            label.configure(image=frame)
            root.after(100, update, index)

        root.after(0, update, 0)
        
        # Auto close after 5 seconds
        root.after(5000, root.destroy)
        root.mainloop()
        
    except Exception as e:
        print(f"тЭМ Error displaying GIF: {e}")
        speak("GIF роХро╛роЯрпНроЯ роорпБроЯро┐ропро╡ро┐ро▓рпНро▓рпИ.")

# --- Spotify Integration Configuration ---
SPOTIFY_SCOPE = "user-modify-playback-state user-read-playback-state playlist-modify-public"

def clear_spotify_cache():
    """Clear Spotify authentication cache"""
    cache_files = [".cache", ".cache-*"]
    for pattern in cache_files:
        import glob
        for cache_file in glob.glob(pattern):
            try:
                os.remove(cache_file)
                print(f"ЁЯЧСя╕П Removed cache file: {cache_file}")
            except Exception as e:
                print(f"тЭМ Could not remove {cache_file}: {e}")

def initialize_spotify():
    """Initialize Spotify client with authentication"""
    try:
        # Clear any existing cache file
        cache_path = ".cache"
        if os.path.exists(cache_path):
            os.remove(cache_path)
            print("ЁЯЧСя╕П Cleared Spotify cache")
        
        sp_oauth = SpotifyOAuth(
            client_id=SPOTIFY_CLIENT_ID,
            client_secret=SPOTIFY_CLIENT_SECRET,
            redirect_uri=SPOTIFY_REDIRECT_URI,
            scope=SPOTIFY_SCOPE,
            cache_path=cache_path
        )
        
        spotify = spotipy.Spotify(auth_manager=sp_oauth)
        return spotify
    except Exception as e:
        print(f"тЭМ Spotify authentication failed: {e}")
        speak("Spotify роЗрогрпИрокрпНрокрпБ родрпЛро▓рпНро╡ро┐ропроЯрпИроирпНродродрпБ.")
        return None

def search_and_play_song_no_auth(song_query):
    """No authentication version - just open Spotify search"""
    try:
        # Direct Spotify web search without API
        search_url = f"https://open.spotify.com/search/{song_query.replace(' ', '%20')}"
        webbrowser.open(search_url)
        
        success_msg = f"{song_query} Spotify роЗро▓рпН родрпЗроЯрокрпНрокроЯрпНроЯродрпБ!"
        print(f"ЁЯМР {success_msg}")
        speak(f"{song_query} Spotify роЗро▓рпН родрпЗроЯрпБроХро┐ро▒рпЗройрпН.")
        log_conversation("Assistant", f"Searched Spotify for: {song_query}")
        return True
        
    except Exception as e:
        error_msg = f"рокро┐ро┤рпИ: {e}"
        print(f"тЭМ {error_msg}")
        speak("Spotify родрпЗроЯро▓ро┐ро▓рпН рокро┐ро┤рпИ.")
        return False

def search_and_play_song_simple(song_query):
    """Simple version - search and open in web browser"""
    try:
        spotify = initialize_spotify()
        if not spotify:
            # Fallback: search on web without authentication
            search_url = f"https://open.spotify.com/search/{song_query.replace(' ', '%20')}"
            webbrowser.open(search_url)
            fallback_msg = f"{song_query} ро╡рпЖрокрпН рокро┐ро│рпЗропро░ро┐ро▓рпН родрпЗроЯрпБроХро┐ро▒рпЗройрпН."
            print(f"ЁЯМР {fallback_msg}")
            speak(fallback_msg)
            return True
        
        print(f"ЁЯФН Searching for: {song_query}")
        speak(f"{song_query} родрпЗроЯрпБроХро┐ро▒рпЗройрпН...")
        
        # Search for the song
        results = spotify.search(q=song_query, type='track', limit=1)
        
        if results['tracks']['items']:
            track = results['tracks']['items'][0]
            track_name = track['name']
            artist_name = track['artists'][0]['name']
            
            print(f"ЁЯО╡ Found: {track_name} by {artist_name}")
            speak(f"{track_name} роХрогрпНроЯрпБрокро┐роЯро┐родрпНродрпЗройрпН. ро╡рпЖрокрпН рокро┐ро│рпЗропро░ро┐ро▓рпН родро┐ро▒роХрпНроХро┐ро▒рпЗройрпН...")
            log_conversation("Assistant", f"Opening: {track_name} by {artist_name}")
            
            # Always open in web browser (simpler approach)
            spotify_url = f"https://open.spotify.com/track/{track['id']}"
            webbrowser.open(spotify_url)
            
            success_msg = f"{track_name} ро╡рпЖрокрпН рокро┐ро│рпЗропро░ро┐ро▓рпН родро┐ро▒роХрпНроХрокрпНрокроЯрпНроЯродрпБ!"
            print(f"тЬЕ {success_msg}")
            speak(success_msg)
            return True
        else:
            not_found_msg = f"{song_query} рокро╛роЯро▓рпН роХрогрпНроЯрпБрокро┐роЯро┐роХрпНроХ роорпБроЯро┐ропро╡ро┐ро▓рпНро▓рпИ."
            print(f"тЭМ {not_found_msg}")
            speak(not_found_msg)
            return False
            
    except Exception as e:
        # Fallback: direct web search
        search_url = f"https://open.spotify.com/search/{song_query.replace(' ', '%20')}"
        webbrowser.open(search_url)
        fallback_msg = f"{song_query} ро╡рпЖрокрпН рокро┐ро│рпЗропро░ро┐ро▓рпН родрпЗроЯрпБроХро┐ро▒рпЗройрпН."
        print(f"ЁЯМР {fallback_msg}")
        speak(fallback_msg)
        return True

def search_and_play_song(song_query):
    """Search for a song on Spotify and play it"""
    try:
        spotify = initialize_spotify()
        if not spotify:
            return False
        
        print(f"ЁЯФН Searching for: {song_query}")
        speak(f"{song_query} родрпЗроЯрпБроХро┐ро▒рпЗройрпН...")
        
        # Search for the song
        results = spotify.search(q=song_query, type='track', limit=1)
        
        if results['tracks']['items']:
            track = results['tracks']['items'][0]
            track_name = track['name']
            artist_name = track['artists'][0]['name']
            track_uri = track['uri']
            
            print(f"ЁЯО╡ Found: {track_name} by {artist_name}")
            speak(f"{track_name} роХрогрпНроЯрпБрокро┐роЯро┐родрпНродрпЗройрпН. роЗроЪрпИроХрпНроХро┐ро▒рпЗройрпН...")
            log_conversation("Assistant", f"Playing: {track_name} by {artist_name}")
            
            # Get available devices
            devices = spotify.devices()
            if devices['devices']:
                # Play the song on the first available device
                device_id = devices['devices'][0]['id']
                spotify.start_playback(device_id=device_id, uris=[track_uri])
                
                success_msg = f"{track_name} роЗроЪрпИроХрпНроХрокрпНрокроЯрпБроХро┐ро▒родрпБ!"
                print(f"тЬЕ {success_msg}")
                speak(success_msg)
                return True
            else:
                # No active device found, open Spotify web player
                spotify_url = f"https://open.spotify.com/track/{track['id']}"
                webbrowser.open(spotify_url)
                
                fallback_msg = "Spotify роЪро╛родройроорпН роЗро▓рпНро▓рпИ. ро╡рпЖрокрпН рокро┐ро│рпЗропро░ро┐ро▓рпН родро┐ро▒роХрпНроХро┐ро▒рпЗройрпН."
                print(f"тЪая╕П {fallback_msg}")
                speak(fallback_msg)
                return True
        else:
            not_found_msg = f"{song_query} рокро╛роЯро▓рпН роХрогрпНроЯрпБрокро┐роЯро┐роХрпНроХ роорпБроЯро┐ропро╡ро┐ро▓рпНро▓рпИ."
            print(f"тЭМ {not_found_msg}")
            speak(not_found_msg)
            return False
            
    except Exception as e:
        error_msg = f"Spotify рокро┐ро┤рпИ: {e}"
        print(f"тЭМ {error_msg}")
        speak("Spotify роЗро▓рпН рокро┐ро┤рпИ роПро▒рпНрокроЯрпНроЯродрпБ.")
        return False

def listen_for_song_request():
    """Listen for song name and search/play it"""
    try:
        recognizer = sr.Recognizer()
        mic = sr.Microphone()
        
        speak("роОроирпНрод рокро╛роЯро▓рпИ роХрпЗроЯрпНроХ ро╡ро┐ро░рпБроорпНрокрпБроХро┐ро▒рпАро░рпНроХро│рпН?")
        print("ЁЯОд Listening for song request...")
        
        with mic as source:
            recognizer.adjust_for_ambient_noise(source)
            audio = recognizer.listen(source, timeout=10)
        
        song_query = recognizer.recognize_google(audio)
        print(f"ЁЯО╡ Song request: {song_query}")
        log_conversation("User", f"Song request: {song_query}")
        
        return search_and_play_song_no_auth(song_query)  # Use no-auth version
        
    except sr.WaitTimeoutError:
        timeout_msg = "роирпЗро░роорпН роорпБроЯро┐роирпНродродрпБ. роорпАрогрпНроЯрпБроорпН роорпБропро▒рпНроЪро┐роХрпНроХро╡рпБроорпН."
        print(f"тП░ {timeout_msg}")
        speak(timeout_msg)
        return False
    except Exception as e:
        error_msg = f"рокро╛роЯро▓рпН роХрпЛро░ро┐роХрпНроХрпИ рокрпБро░ро┐роирпНродрпБроХрпКро│рпНро│ роорпБроЯро┐ропро╡ро┐ро▓рпНро▓рпИ: {e}"
        print(f"тЭМ {error_msg}")
        speak("рокро╛роЯро▓рпН роХрпЛро░ро┐роХрпНроХрпИ рокрпБро░ро┐роирпНродрпБроХрпКро│рпНро│ роорпБроЯро┐ропро╡ро┐ро▓рпНро▓рпИ.")
        return False

# Function to open gesture recognition window
def open_gesture_window():
    try:
        gesture_script_path = os.path.join(os.getcwd(), "gesture", "gesture.py")
        if os.path.exists(gesture_script_path):
            subprocess.Popen(["python", gesture_script_path])
            speak("роХрпИ роЪрпИроХрпИ ро╡ро┐рогрпНроЯрпЛ родро┐ро▒роХрпНроХрокрпНрокроЯрпБроХро┐ро▒родрпБ...")
            log_conversation("Assistant", "роХрпИ роЪрпИроХрпИ ро╡ро┐рогрпНроЯрпЛ родро┐ро▒роХрпНроХрокрпНрокроЯрпБроХро┐ро▒родрпБ...")
        else:
            speak("роХрпИ роЪрпИроХрпИ роХрпЛрокрпНрокрпБ роХро╛рогро╡ро┐ро▓рпНро▓рпИ.")
            log_conversation("Assistant", "роХрпИ роЪрпИроХрпИ роХрпЛрокрпНрокрпБ роХро╛рогро╡ро┐ро▓рпНро▓рпИ.")
            print(f"[ERROR] Gesture file not found: {gesture_script_path}")
    except Exception as e:
        speak("роХрпИ роЪрпИроХрпИ роорпБро▒рпИ роЪрпЖропро▓рпНрокроЯро╡ро┐ро▓рпНро▓рпИ.")
        log_conversation("Assistant", "роХрпИ роЪрпИроХрпИ роорпБро▒рпИ роЪрпЖропро▓рпНрокроЯро╡ро┐ро▓рпНро▓рпИ.")
        print(f"[ERROR] Failed to open gesture window: {e}")

# Tamil to Hindi translation loop
def tamil_to_hindi_loop():
    speak("родрооро┐ро┤ро┐ро▓рпН рокрпЗроЪрпБроЩрпНроХро│рпН. ро╣ро┐роирпНродро┐ропро┐ро▓рпН роорпКро┤ро┐рокрпЖропро░рпНроХрпНроХрокрпНрокроЯрпБроХро┐ро▒родрпБ. роиро┐ро▒рпБродрпНрод 'niruthu' роЕро▓рпНро▓родрпБ 'stop' роОройрпНро▒рпБ роЪрпКро▓рпНро▓рпБроЩрпНроХро│рпН.")
    log_conversation("Assistant", "родрооро┐ро┤ро┐ро▓рпН рокрпЗроЪрпБроЩрпНроХро│рпН. ро╣ро┐роирпНродро┐ропро┐ро▓рпН роорпКро┤ро┐рокрпЖропро░рпНроХрпНроХрокрпНрокроЯрпБроХро┐ро▒родрпБ. роиро┐ро▒рпБродрпНрод 'niruthu' роЕро▓рпНро▓родрпБ 'stop' роОройрпНро▒рпБ роЪрпКро▓рпНро▓рпБроЩрпНроХро│рпН.")
    print("ЁЯЯв Tamil тЮбя╕П Hindi translator running. Say something in Tamil.")
    while True:
        input_text = recognize_speech()
        log_conversation("User", input_text)

        if input_text.lower() in ["niruthu", "stop", "exit","роиро┐ро▒рпБродрпНродрпБ", "роиро┐ро▒рпНроХро╡рпБроорпН", "ро╡рпЖро│ро┐ропрпЗро▒рпБ", "ро╡рпЖро│ро┐ропрпЗ"]:
            speak("роорпКро┤ро┐рокрпЖропро░рпНрокрпНрокрпБ роиро┐ро▒рпБродрпНродрокрпНрокроЯрпНроЯродрпБ.")
            log_conversation("Assistant", "роорпКро┤ро┐рокрпЖропро░рпНрокрпНрокрпБ роиро┐ро▒рпБродрпНродрокрпНрокроЯрпНроЯродрпБ.")
            print("ЁЯЫС Exiting translator.")
            break

        if input_text.strip() == "":
            continue

        print(f"ЁЯЧгя╕П Tamil: {input_text}")
        hindi_output = translate_tamil_to_hindi(input_text)
        print(f"ЁЯУЭ Hindi: {hindi_output}")
        log_conversation("Assistant", hindi_output)
        speak_text(hindi_output)

# Process user commands
def process_command(command):
    if not command:
        return

    print(f"[USER COMMAND]: {command}")
    log_conversation("User", command)

    # If gesture command
    if any(kw in command.lower() for kw in ["gesture", "роХрпИ роЪрпИроХрпИ", "open gesture", "start gesture"]):
        open_gesture_window()
        return

    # If GIF display command
    if any(kw in command.lower() for kw in ["gif", "show gif", "display gif", "GIF роХро╛роЯрпНроЯрпБ", "gif роХро╛роЯрпНроЯрпБ"]):
        listen_and_show_gif()
        return

    # If Spotify/music command
    if any(kw in command.lower() for kw in ["play song", "play music", "spotify", "рокро╛роЯро▓рпН роЗроЪрпИ", "роЗроЪрпИ роЗроЪрпИ", "song play", "music play"]):
        listen_for_song_request()
        return

    # If direct song search (contains "play" + song name)
    if "play" in command.lower() and len(command.split()) > 1:
        # Extract song name after "play"
        parts = command.lower().split("play", 1)
        if len(parts) > 1:
            song_name = parts[1].strip()
            if song_name:
                search_and_play_song_no_auth(song_name)  # Use no-auth version
                return

    # If user wants translator mode
    if any(kw in command.lower() for kw in ["translator", "translate", "роорпКро┤ро┐рокрпЖропро░рпНрокрпНрокрпБ", "tamil to hindi"]):
        tamil_to_hindi_loop()
        return

    # If general task command
    if execute_command(command):
        log_conversation("Assistant", "Executed general task command.")
        return

    # If none of the above, use Gemini AI to respond
    response = get_response(command)
    log_conversation("Assistant", response)
    speak(response)

# Entry point
if __name__ == "__main__":
    welcome_msg = "ро╡рогроХрпНроХроорпН! роиро╛ройрпН роЬро╛ро░ро╛. роЗройрпНро▒рпБ роиро╛ройрпН роЙроЩрпНроХро│рпБроХрпНроХрпБ роОрокрпНрокроЯро┐ роЙродро╡ роорпБроЯро┐ропрпБроорпН? роХрпИ роЪрпИроХрпИ, роорпКро┤ро┐рокрпЖропро░рпНрокрпНрокрпБ, GIF роХро╛роЯрпНроЯ, роЕро▓рпНро▓родрпБ рокро╛роЯро▓рпН роЗроЪрпИроХрпНроХ роЪрпКро▓рпНро▓рпБроЩрпНроХро│рпН!"
    speak(welcome_msg)
    log_conversation("Assistant", welcome_msg)
    while True:
        command = listen()
        process_command(command)